# ðŸ”¢ Vector Processing & Storage Guide

HÆ°á»›ng dáº«n chi tiáº¿t vá» cÃ¡ch xá»­ lÃ½ vector embeddings vÃ  lÆ°u vÃ o Supabase.

## ðŸ“Š Flow Tá»•ng Quan

```
1. Extract Text from File (PDF/Word)
   â”‚
   â–¼
2. Clean & Normalize Text
   â”‚
   â–¼
3. Generate Embeddings with Gemini AI
   â”‚ (Output: Array of 768 numbers)
   â”‚
   â–¼
4. Convert to jsonb[] format
   â”‚ (Wrap: [array] â†’ jsonb[])
   â”‚
   â–¼
5. Save to Supabase knowledge_base
   â”‚
   â””â”€â–º Vector stored as jsonb[]
```

## ðŸ”§ Chi Tiáº¿t Tá»«ng BÆ°á»›c

### BÆ°á»›c 1: Extract Text
```javascript
// Tá»« PDF
const rawText = await fileProcessor.extractFromPDF(fileBuffer);

// Tá»« Word
const rawText = await fileProcessor.extractFromWord(fileBuffer);
```

**Output**: Raw text string

### BÆ°á»›c 2: Clean Text
```javascript
const cleanedText = fileProcessor.cleanText(rawText);
```

**Xá»­ lÃ½**:
- Remove multiple spaces â†’ single space
- Remove multiple newlines â†’ single newline
- Trim whitespace

**Output**: Cleaned text string

### BÆ°á»›c 3: Generate Embeddings

```javascript
const embeddings = await geminiService.generateEmbeddings(cleanedText);
```

**Chi tiáº¿t**:
- Model: `embedding-001` (Gemini)
- Input: Text (max 20,000 chars)
- Output: Array of 768 floating point numbers
- Dimensions: 768

**Example output**:
```javascript
[
  0.0123456789,
  -0.0234567890,
  0.0345678901,
  // ... 765 more numbers
]
```

### BÆ°á»›c 4: Convert to jsonb[] Format

```javascript
// In Supabase service
const embeddingJsonb = document.embedding ? [document.embedding] : null;
```

**LÃ½ do**: 
- Database column type: `jsonb[]`
- Cáº§n wrap array trong array: `[embedding]`

**Format lÆ°u vÃ o DB**:
```javascript
// TrÆ°á»›c: 768 numbers
[0.012, -0.023, 0.034, ...]

// Sau: Wrap trong array
[[0.012, -0.023, 0.034, ...]]
```

### BÆ°á»›c 5: Save to Supabase

```javascript
const recordData = {
  title: "Document Title",
  content: "Full text content...",
  file_name: "document.pdf",
  file_type: "pdf",
  embedding: embeddingJsonb,  // [[768 numbers]]
  metadata: {
    driveFileId: "xyz123",
    size: 245300,
    mimeType: "application/pdf",
    textLength: 5000
  },
  chunk_index: 0,
  teacher_id: null,
  user_id: null
};

await supabase.from('knowledge_base').insert(recordData);
```

## ðŸ“ Vector Dimensions

Gemini `embedding-001` táº¡o vectors vá»›i **768 dimensions**:

```
[dâ‚€, dâ‚, dâ‚‚, ... dâ‚‡â‚†â‚‡]
```

Má»—i dimension lÃ  má»™t sá»‘ thá»±c (float) tá»« -1 Ä‘áº¿n 1.

## ðŸ’¾ Database Storage

### Table Schema
```sql
embedding jsonb[] null
```

### Stored Format
```json
[
  [0.012, -0.023, 0.034, ..., 0.078]
]
```

LÃ  má»™t array chá»©a má»™t array (jsonb[])

### Táº¡i sao jsonb[] thay vÃ¬ vector(768)?

**Hiá»‡n táº¡i**: `jsonb[]`
- âœ… Flexible, khÃ´ng cáº§n pgvector extension
- âš ï¸ Slower for similarity search (calculate in app)
- âœ… Works out of the box

**Future upgrade**: `vector(768)` (pgvector)
- âœ… Much faster similarity search (10-100x)
- âœ… Native PostgreSQL operations
- âš ï¸ Requires migration (see MIGRATION.md)

## ðŸ” Similarity Search

### Current Method (jsonb[])

```javascript
// Fetch all documents
const { data: allDocs } = await supabase
  .from('knowledge_base')
  .select('*')
  .not('embedding', 'is', null);

// Calculate cosine similarity in JavaScript
const results = allDocs
  .map(doc => {
    const docEmbedding = doc.embedding[0]; // Get array from jsonb[]
    const similarity = cosineSimilarity(queryEmbedding, docEmbedding);
    return { ...doc, similarity };
  })
  .filter(doc => doc.similarity > 0.5)
  .sort((a, b) => b.similarity - a.similarity)
  .slice(0, 10);
```

### Cosine Similarity Formula

```javascript
function cosineSimilarity(a, b) {
  let dotProduct = 0;
  let normA = 0;
  let normB = 0;

  for (let i = 0; i < a.length; i++) {
    dotProduct += a[i] * b[i];
    normA += a[i] * a[i];
    normB += b[i] * b[i];
  }

  return dotProduct / (Math.sqrt(normA) * Math.sqrt(normB));
}
```

**Output**: Value tá»« -1 Ä‘áº¿n 1
- `1.0` = Giá»‘ng há»‡t
- `0.5` = TÆ°Æ¡ng Ä‘á»‘i giá»‘ng
- `0.0` = KhÃ´ng liÃªn quan
- `-1.0` = NgÆ°á»£c láº¡i hoÃ n toÃ n

## ðŸ“Š Example Data

### Input Document
```
File: "Product Catalog 2024.pdf"
Size: 1.2 MB
Content: "Our company offers premium vegetables including tomatoes, 
          cucumbers, and bell peppers. All products are organic..."
```

### Processing
```javascript
// 1. Extract text
text = "Our company offers premium vegetables..."

// 2. Generate embeddings
embeddings = [0.0234, -0.0156, 0.0789, ..., 0.0123] // 768 numbers

// 3. Store in database
{
  title: "Product Catalog 2024",
  file_name: "Product Catalog 2024.pdf",
  content: "Our company offers premium vegetables...",
  embedding: [[0.0234, -0.0156, 0.0789, ..., 0.0123]]
}
```

### Query & Search
```javascript
// Query: "organic vegetables"
queryEmbedding = [0.0245, -0.0167, 0.0801, ..., 0.0134]

// Similarity calculation
similarity = cosineSimilarity(queryEmbedding, docEmbedding)
// Result: 0.87 (High similarity! âœ…)
```

## âš¡ Performance

### Current (jsonb[])
- âœ… 10-100 documents: < 100ms
- âš ï¸ 100-1000 documents: 1-5s
- âŒ 1000+ documents: > 5s

### With pgvector (recommended for scale)
- âœ… 10-100 documents: < 10ms
- âœ… 100-1000 documents: 10-50ms
- âœ… 1000-100K documents: 50-200ms
- âœ… 100K-1M documents: 200-500ms

**Recommendation**: Náº¿u cÃ³ > 1000 documents, xem [MIGRATION.md](MIGRATION.md) Ä‘á»ƒ upgrade lÃªn pgvector.

## ðŸ§ª Testing Vector Processing

### Test 1: Generate Embeddings
```bash
# Test táº¡o embeddings tá»« text
node -e "
import('./src/services/gemini.js').then(async ({ default: gemini }) => {
  await gemini.initialize();
  const embeddings = await gemini.generateEmbeddings('test text');
  console.log('Dimensions:', embeddings.length);
  console.log('First 5 values:', embeddings.slice(0, 5));
});
"
```

### Test 2: Full Pipeline
```bash
# Run sync má»™t file Ä‘á»ƒ test
npm start once
```

### Test 3: Search
```bash
# Test tÃ¬m kiáº¿m
npm run search "test query"
```

## ðŸ”§ Troubleshooting

### Issue 1: "embedding is null"

**NguyÃªn nhÃ¢n**: Gemini API failed hoáº·c text quÃ¡ dÃ i

**Fix**:
```javascript
// Check text length before generating
if (cleanedText.length > 20000) {
  cleanedText = cleanedText.substring(0, 20000);
}
```

### Issue 2: "Invalid embedding format"

**NguyÃªn nhÃ¢n**: Embedding khÃ´ng pháº£i array

**Fix**:
```javascript
// Verify embeddings is array
if (!Array.isArray(embeddings) || embeddings.length !== 768) {
  throw new Error('Invalid embeddings format');
}
```

### Issue 3: "Search returns no results"

**NguyÃªn nhÃ¢n**: 
1. Embeddings chÆ°a Ä‘Æ°á»£c táº¡o
2. Similarity threshold quÃ¡ cao

**Fix**:
```javascript
// Lower threshold
.filter(doc => doc.similarity > 0.3) // Instead of 0.5
```

## ðŸ“š Best Practices

### 1. Text Preprocessing
```javascript
// Clean text before embedding
text = text
  .toLowerCase()           // Normalize case
  .replace(/\s+/g, ' ')   // Single spaces
  .trim();                 // Remove edges
```

### 2. Chunk Long Documents
```javascript
// For documents > 20K chars
const chunks = gemini.splitTextIntoChunks(text, 5000);
const embeddings = await gemini.generateBatchEmbeddings(chunks);
// Store each chunk separately with chunk_index
```

### 3. Error Handling
```javascript
try {
  const embeddings = await gemini.generateEmbeddings(text);
} catch (error) {
  console.error('Failed to generate embeddings:', error);
  // Skip this document or retry
  return;
}
```

### 4. Rate Limiting
```javascript
// Add delay between API calls
await new Promise(resolve => setTimeout(resolve, 500));
```

## ðŸŽ¯ Summary

**Vector Processing Flow**:
1. Text extraction â†’ 2. Cleaning â†’ 3. Embeddings (768d) â†’ 4. jsonb[] format â†’ 5. Save to DB

**Key Points**:
- âœ… Gemini embedding-001: 768 dimensions
- âœ… Storage: jsonb[] (flexible, slower search)
- âœ… Search: JavaScript cosine similarity
- âš¡ Upgrade option: pgvector for better performance

**Next Steps**:
- Run `npm start once` to process files
- Use `npm run search "query"` to test search
- Monitor performance with many documents
- Consider pgvector migration if needed

---

Questions? Check [MIGRATION.md](MIGRATION.md) for pgvector upgrade guide!


